---
title: "Klasyfikacja ozon"
author: "Marysia"
format: 
  html:
    self-contained: true
    embed-resources: true
    toc: true
    toc-depth: 4
    toc-location: right
    toc-title: "Spis treści"
    number-sections: true
    number-depth: 4
    code-fold: show
    code-summary: "Show the code"
    code-tools: true
    code-block-bg: true
    code-block-border-left: "black"
    code-line-numbers: false
    code-copy: true
    html-math-method: katex
    smooth-scroll: true
    anchor-sections: true
    link-external-icon: true
    link-external-newwindow: true
    theme:
        light: cosmo
        dark: darkly
    fontsize: 1.0em
    linestretch: 1.5
execute:
  warning: false
  echo: true
  error: false
---
Czy stężenie ozonu było wysokie, czy niskie?

```{r}
library(tidymodels) 
library(skimr) 
library(GGally) 
library(openair) 
library(ranger)
tidymodels_prefer()
```
# Analiza
```{r}
air <- mydata |> selectByDate(year = 2002) 
air |> skim()
```

```{r}
air <- air |> na.omit()
```

```{r}
set.seed(222)
air[sample(1:nrow(air), size = 300, replace = F),] |> 
  select(nox, no2) |> 
  ggpairs()
```

```{r}
library(ggpubr)
# wykres regresji liniowej, do sprawdzenia danych 
set.seed(222)
air[sample(1:nrow(air), size = 300, replace = F),] |> 
  select(nox, no2) |> 
  ggplot(aes(nox, no2)) +
  geom_point() +
  geom_smooth(method = "lm", se = T, formula = y ~ x) + 
  stat_cor(label.x = 10, label.y = 80) + 
  stat_regline_equation(label.x = 10, label.y = 85) +
  theme_bw()
```

 nox i no2 są mocno skorelowane
 
```{r}
air |>    
  ggplot(aes(date, o3)) +     
  geom_line() +     
  theme_bw()
```
zakladam ze niskie to <10, a wysokie to >
```{r}
air |> 
  pull(o3) |> 
  range()  
```

```{r}
air <-
  air |>
  mutate(ozone = cut(
    o3,
    breaks = c(-0.1, 10, 53),
    labels = c("Niskie", "Wysokie")
  ))
```

```{r}
air |> count(ozone)
```
# Modele
```{r}
set.seed(222)
data_split <- initial_split(air, strata = ozone)
train_data <- training(data_split)
test_data <- testing(data_split)
```


```{r}
ozon_rec <- recipe(ozone ~ ., data = train_data) |>
  update_role(date, new_role = "ID") |> 
  step_rm(nox) |>  # kolinearnosc z no2 - nic nie wnosi
  step_rm(o3) |> 
  step_date(date, features = c("month", "dow")) |>
  step_dummy(all_nominal_predictors()) |>
  step_YeoJohnson(all_numeric_predictors()) |> 
  step_zv(all_predictors())
```

```{r}
ozon_rec |> summary()
```

```{r}
ozon_rec |> prep()
```
Zwykła regresja logistyczna
```{r}
lr_mod <- logistic_reg() |> 
  set_engine("glm") |> 
  set_mode("classification")

logi_work <- 
  workflow() |> 
  add_model(lr_mod) |> 
  add_recipe(ozon_rec)

logi_work
```

Model lasu losowego z vkrotną walidacją
```{r}
set.seed(345)
folds <- vfold_cv(data = train_data, v = 10)

rf_mod <- rand_forest() |>
  set_engine("ranger") |>
  set_mode("classification")

rf_wf <- workflow() |>
  add_model(rf_mod) |>
  add_recipe(ozon_rec)
```

```{r}
set.seed(456)
rf_fit_rs <- 
  rf_wf |> 
  fit_resamples(folds)

rf_fit_rs
```
V-krotna walidacja dla regresji logistycznej
```{r}
logi_fit_rs <- 
  logi_work |> 
  fit_resamples(folds)

logi_fit_rs
```


```{r}
logi_fit <-  
  logi_work |> 
  fit(data = train_data)

ozon_rec |> summary()
```

```{r}
logi_fit |> 
  extract_fit_parsnip() |> 
  tidy()
```


```{r}
predict(logi_fit, test_data)
```

```{r}
logi_preds <- predict(logi_fit, test_data, type = "prob") |> 
  bind_cols(predict(logi_fit, test_data)) |> 
  bind_cols(test_data |> select(ozone))

head(logi_preds)

```
```{r}
logi_preds |> 
  metrics(truth = ozone, estimate = .pred_class)

logi_preds |> 
  conf_mat(truth = ozone, estimate = .pred_class)
```


```{r}
logi_preds  |> 
  roc_curve(truth = ozone, .pred_Wysokie) |> 
  autoplot()
```


```{r}
rf_fit_rs |> 
  collect_metrics() |> 
  knitr::kable(digits = 3)
```


```{r}
logi_fit_rs |> 
  collect_metrics() |> 
  knitr::kable(digits = 3)
```


Bootstrap dla regresji
```{r}
bootstraps <- bootstraps(train_data, times = 25, strata = ozone)

logi_boot <- 
  fit_resamples(
    logi_work,
    resamples = bootstraps
  )

logi_boot |> collect_metrics() |> knitr::kable(digits = 3)
```

Boostrap dla lasu
```{r}
rf_boot <- 
  fit_resamples(
    rf_wf,
    resamples = bootstraps
  )

rf_boot |> collect_metrics() |> knitr::kable(digits = 3)
```


```{r}
bind_rows(
  collect_metrics(logi_fit_rs) |> mutate(model = "Logistic - CV"),
  collect_metrics(rf_fit_rs)   |> mutate(model = "Random Forest - CV"),
  collect_metrics(logi_boot)   |> mutate(model = "Logistic - Bootstrap"),
  collect_metrics(rf_boot)     |> mutate(model = "Random Forest - Bootstrap")
) |> 
  knitr::kable(digits = 3)

```

# Wnioski
Las losowy wypada lepiej niż regresja logistyczna - i przy cv i przy bootstrapie. Std_err jest dobre dla obydwu modeli, lecz dla metod bootstrapowych 
zmniejsza ich wartość jeszcze bardziej. Zarówno walidacja krzyżowa, jak i bootstrap dały bardzo zbliżone wyniki, to dobry rezultat, który świadczy o stabilności i powtarzalności modeli, a także o tym, że są one dobrze dopasowane i nie wykazują dużego wpływu przypadkowości danych uczących. Niższy Brier score dla modelu lasu losowego mówi o tym, że przewidywane prawdopodobieństwa są bliższe rzeczywistemu rozkładowi klas niż w przypadku regresji logistycznej. Dzięki resampligowi obniża się ryzyko przeuczenia.

